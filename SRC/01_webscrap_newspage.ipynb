{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_webscrap_newspage.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wy5DIAaoSFc",
        "outputId": "646e76d7-b67a-40e3-d0e8-970cd864edef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries\n"
      ],
      "metadata": {
        "id": "e5s3zC8z8WNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "metadata": {
        "id": "QjsfjnJZ8o66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml.html import document_fromstring\n",
        "import re"
      ],
      "metadata": {
        "id": "Q6v7J__V89tP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connection 'cause I used Google colab."
      ],
      "metadata": {
        "id": "nxxaFFZK8swd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive conection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM7T_Sdw41z4",
        "outputId": "4e172832-d46b-4a79-f970-5bc2995bb2d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "7JFMzZ_M89ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In case of more than one author:\n",
        "def concatenate_authors(list):\n",
        "    result_aux = ''\n",
        "    for element in list:\n",
        "        result_aux += ' AND ' + str(element[0])\n",
        "\n",
        "    nchar = len(result_aux)\n",
        "    result = result_aux[5:nchar]    \n",
        "    return result\n",
        "\n",
        "\n",
        "# ArticleID\n",
        "def regex_id(string):\n",
        "  pattern = re.compile(r'\"\\d{16}\"') \n",
        "  result = pattern.match(string)\n",
        "  if result:\n",
        "    return  result.group()\n",
        "  return None\n",
        "\n",
        "\n",
        "# Paste all elements of a list into a single string\n",
        "# https://www.w3resource.com/python-exercises/python-basic-exercise-27.php\n",
        "def concatenate_list_data(list):\n",
        "    result = ''\n",
        "    for element in list:\n",
        "        result += str(element)\n",
        "    return result\n",
        "\n",
        "\n",
        "# To save data with its important information\n",
        "def save_data(TITLE, SUBTITLE, TEXT, ARTICLEID, AUTHOR, DATE, EDIT, PATH_SAVE):\n",
        "  text_final = TITLE + '. ' + SUBTITLE + '. ' + TEXT\n",
        "\n",
        "  # Write line to file\n",
        "  name_save = str(ARTICLEID) + '_' + AUTHOR + '_' + DATE + '_' + EDIT  + '.txt' \n",
        "  \n",
        "  with open(PATH_SAVE + name_save, 'w') as writefile:\n",
        "    writefile.write(text_final)\n",
        "\n",
        "\n",
        "def scrap_newspage_save_file(WEBPAGE, PATH_SAVE):\n",
        "  resposta = requests.get(WEBPAGE)\n",
        "  html = resposta.content\n",
        "  # Encoding\n",
        "  html = html.decode(\"UTF-8\")\n",
        "  # Tree\n",
        "  arvore = document_fromstring(html)\n",
        "\n",
        "  # Title tag\n",
        "  tags_head = arvore.xpath(\"//title\")\n",
        "  title_info = []\n",
        "  for tag in tags_head:\n",
        "    tit = tag.xpath(\"text()\")[-0]\n",
        "    tit = str(tit)\n",
        "    if re.findall('\\d{2}/\\d{2}/\\d{4}', tit):\n",
        "      title_info.append(tit) \n",
        "  \n",
        "  # Get some parameters\n",
        "  param = title_info[0].split(\"-\")\n",
        "  \n",
        "  title = param[0].strip()\n",
        "  date = param[1].strip()\n",
        "  pattern = re.compile(r\"/\")\n",
        "  date = pattern.sub(\"-\", date)\n",
        "  edit = param[2].strip()\n",
        "\n",
        "  # Subtitle\n",
        "  ## <meta name=\"description\" content=\"José Aparecido Alves Filho havia sido condenado a 21 anos por latrocínio\">\n",
        "  tags_subtit = arvore.xpath('//meta[@name=\"description\"]')\n",
        "\n",
        "  subtitle = []\n",
        "  for tag in tags_subtit:\n",
        "    subtit = tag.attrib.get(\"content\")\n",
        "    subtitle.append(subtit)\n",
        "\n",
        "  subtitle = subtitle[0].strip()\n",
        "\n",
        "  # Author\n",
        "  tags_author = arvore.xpath('//div[@class=\"c-signature\"]/strong/a')\n",
        "\n",
        "  author_aux = []\n",
        "  for tag in tags_author:\n",
        "    assin = tag.xpath(\"text()\")\n",
        "    author_aux.append(assin)\n",
        "\n",
        "  # In case of more than one author:\n",
        "  author = concatenate_authors(author_aux) \n",
        "\n",
        "  # Article ID\n",
        "  html_split = html.split('\"articleId\": ')\n",
        "  articleId_aux = html_split[1]\n",
        "  articleId = regex_id(articleId_aux)[1:16] \n",
        "\n",
        "  # Text\n",
        "  tags_p = arvore.xpath('//div[@class=\"c-news__body\"]//p')\n",
        "  paragrafo = []\n",
        "\n",
        "  for tag in tags_p:\n",
        "    parag = tag.xpath(\"text()\")\n",
        "    if len(parag):\n",
        "      parag_final = concatenate_list_data(parag)\n",
        "      paragrafo.append(parag_final)\n",
        "\n",
        "  text = concatenate_list_data(paragrafo) \n",
        "\n",
        "  # Save\n",
        "  save_data(title, \n",
        "          subtitle, \n",
        "          text, \n",
        "          articleId, \n",
        "          author, \n",
        "          date, \n",
        "          edit, \n",
        "          PATH_SAVE)"
      ],
      "metadata": {
        "id": "UxYLuiij8t3T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the function to data"
      ],
      "metadata": {
        "id": "oS6gWH6k9CjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scrap_newspage_save_file(\"https://www1.folha.uol.com.br/cotidiano/2022/01/apos-reportagem-da-folha-justica-absolve-lavrador-que-ficou-preso-por-7-anos.shtml\", \n",
        "                         '/content/drive/MyDrive/INSPER/03_trabfinal_1certif/DATA/Processed/')"
      ],
      "metadata": {
        "id": "EzIdfAyS5hlj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrap_newspage_save_file(\"https://www1.folha.uol.com.br/mundo/2022/01/coreia-do-norte-diz-que-fez-novo-teste-de-missil-hipersonico.shtml?origin=folha\", \n",
        "                         '/content/drive/MyDrive/INSPER/03_trabfinal_1certif/DATA/Processed/')"
      ],
      "metadata": {
        "id": "bdwE7vfS7g6B"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}